
<!DOCTYPE html>
<html lang="en"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<!--[if IE]><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><![endif]-->
<title>Yoni Kasten's Homepage</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<meta name="description" content="A PhD student at the Weizmann institute of science, supervised by Prof. Ronen Basri." />
<meta name="author" content="Yoni Kasten" />

<!-- favicons -->
<!-- <link rel="shortcut icon" href="images/templatemo_favicon.ico"> -->
<!-- bootstrap core CSS -->
<link href="js/bootstrap.css" rel="stylesheet">
<!-- fancybox CSS -->
<link href="js/jquery.css" rel="stylesheet">
<!-- flex slider CSS -->
<link href="js/flexslider.css" rel="stylesheet">
<!-- custom styles for this template -->
<link href="js/templatemo_style.css" rel="stylesheet">
<!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
<script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
<![endif]-->
		<style>
			#cf3 {
			align:left
			position:relative;
			width:240px;
			margin:0 auto;
			}
			
			#cf3 img {
			position:absolute;
			left:0;
			-webkit-transition: opacity 0.1s ease-in-out;
			-moz-transition: opacity 0.1s ease-in-out;
			-o-transition: opacity 0.1s ease-in-out;
			transition: opacity 0.1s ease-in-out;
			}
			
			@keyframes cf3FadeInOut {
			0% {
			opacity:1;
			}
			45% {
			opacity:1;
			}
			55% {
			opacity:0;
			}
			100% {
			opacity:0;
			}
			}
			
			#cf3 img.top {
			animation-name: cf3FadeInOut;
			animation-timing-function: ease-in-out;
			animation-iteration-count: infinite;
			animation-duration: 1s;
			animation-direction: alternate;
			}
			
		</style>

</head>
<body>
<header>
    <div class="container">
        <div class="row">
            
            <div class="col-md-3 hidden-xs"></div>
            <div class="col-xs-3 col-xs-offset-20 visible-xs">
                <a href="#" id="mobile_menu"><span class="glyphicon glyphicon-align-justify"></span></a>
            </div>
            <div class="col-xs-24 visible-xs" id="mobile_menu_list">
                <ul style="display: none;">
					<li><a href="#templatemo_about" class="current">About</a></li>
                    <!-- <li><a href="#templatemo_slideshow">Slideshow</a></li> -->
                    <li><a href="#templatemo_publications">Publications</a></li>
                </ul>
            </div>
            <div class="col-md-16 col-sm-18 hidden-xs" id="templatemo-nav-bar">
                <ul class="nav navbar-right">
					<li><a href="#templatemo_about" class="current">About</a></li>
                    <!-- <li><a href="#templatemo_slideshow">Slideshow</a></li> -->
                    <li><a href="#templatemo_publications">Publications</a></li>
                </ul>
            </div>
        </div>
    </div>
</header><!-- end of templatemo_header -->

<section id="templatemo_about">
    <div class="container">
        <div class="row">
            <div class="col-md-2"></div>	
            <div id="my_photo" class="col-md-4 col-sm-7 col-xs-24">
                <img src="images/profile2.jpg" alt="image 1">
            </div>
            <div class="col-md-1"></div>	
            <div class="col-md-16">
                <h2>Yoni Kasten</h2>
				<p>
				I am currently a PhD student at Weizmann Institute of Science
				under the supervision of <a href="http://www.weizmann.ac.il/math/ronen/home/" target="_blank">Prof. Ronen Basri</a> from the Department of Computer Science and Applied Mathematics at the Weizmann Institute of Science. 
				I did my B.Sc. in Electrical Engineering at the Hebrew University of Jerusalem, where I also did my M.Sc. in Computer Science under the supervision of <a href="https://www.cs.huji.ac.il/~peleg/" target="_blank">Prof. Shmuel Peleg</a> and <a href="https://www.cse.huji.ac.il/~werman/" target="_blank">Prof. Michael Werman. </a>
				<br><b>Research interests:</b> 
				<br>I'm interested in Computer Vision and Machine Learning. 
				My PhD research includes both 3D computer vision (e.g. Camera Localization, Structure From Motion) and Deep Learning Theory.</br>
				<br><font size=1></font></br><br>
				<b>Email:</b> yonikasten <font color="grey">at</font> gmail <font color="grey">dot</font> com</br>
				</p>
            </div>
        </div><!-- end of row -->
    </div> 
</section><!-- end of templatemo_about -->




<section id="templatemo_publications">
    <div class="container">
		<hr>
        <div class="row">
            <h1>Publications</h1>
        </div>

		<div class="row" id="templatemo_publications_LargeScaleBD">
		<div class="col-md-1"></div>	
		<div class="col-md-5 col-sm-7 col-xs-24">
			<img src="images/nips2019.PNG" alt="image 1">
		</div>
		<div class="col-md-1"></div>	
		<div class="col-md-16">
			<h2>The Convergence Rate of Neural Networks for</h2>
			<h2>Learned Functions of Different Frequencies</h2>
			<p>Ronen Basri, David Jacobs, Yoni Kasten and Shira Kritchman<p>
			<tab1>  </tab1>
			<p><i>Neural Information Processing Systems (NeurIPS'19), Vancouver 2019</i></p> 
			</p>
			<!--<a class="btn btn-default abstract" ptitle="Abstract will be available soon...">Abstract</a>-->
			<a class="btn btn-default abstract" ptitle="The Convergence Rate of Neural Networks for
Learned Functions of Different Frequencies" 
				abstract="We study the relationship between the speed at which a neural network learns a
function and the frequency of the function. We build on recent results that show
that the dynamics of overparameterized neural networks trained with gradient descent can be well approximated by a linear system. When normalized training
data is uniformly distributed on a hypersphere, the eigenfunctions of this linear
system are spherical harmonic functions. We derive the corresponding eigenvalues for each frequency after introducing a bias term in the model. This bias term
had been omitted from the linear network model without significantly affecting
previous theoretical results. However, we show theoretically and experimentally
that a shallow neural network without bias cannot learn simple, low frequency
functions with odd frequencies, in the limit of large amounts of data. Our results
enable us to make specific predictions of the time it will take a network with bias
to learn functions of varying frequency. These predictions match the behavior of
real shallow and deep networks.
">Abstract</a>
			<a href="https://arxiv.org/pdf/1906.00425.pdf" target="_blank" class="btn btn-default abstract" ptitle="The Convergence Rate of Neural Networks for
Learned Functions of Different Frequencies">Paper</a>
			<!--<a href="https://github.com/YuvalBahat/Confidence_From_Invariance" class="btn btn-default">Code</a>-->
		</div>
        </div>
		
		
		<div class="row" id="templatemo_publications_LargeScaleBD">
		<div class="col-md-1"></div>	
		<div class="col-md-5 col-sm-7 col-xs-24">
			<img src="images/iccv2019.png" alt="image 1">
		</div>
		<div class="col-md-1"></div>	
		<div class="col-md-16">
			<h2>Algebraic Characterization of Essential Matrices </h2>
			<h2>and Their Averaging in Multiview Settings</h2>
			<p>Yoni Kasten*, Amnon Geifman*, Meirav Galun and  Ronen Basri  (*equal contribution)<p>
			<tab1>  </tab1>
			<p><i>International Conference on Computer Vision (ICCV'19), Seoul 2019</i></p> 
			</p>
			<!--<a class="btn btn-default abstract" ptitle="Abstract will be available soon...">Abstract</a>-->
			<a class="btn btn-default abstract" ptitle="Algebraic Characterization of Essential Matrices and Their Averaging
in Multiview Settings" 
				abstract="Essential matrix averaging, i.e., the task of recovering camera locations and orientations in calibrated, multiview settings, is a first step in global approaches to Euclidean structure from motion. A common approach to essential matrix averaging is to separately solve for camera orientations and subsequently for camera positions. This paper presents a novel approach that solves  simultaneously for both camera orientations and positions. We offer a complete characterization of the algebraic conditions that enable a unique Euclidean reconstruction of $n$ cameras from a collection of $(^n_2)$ essential matrices. We next use these conditions to formulate essential matrix averaging as a constrained optimization problem, allowing us to recover a consistent set of essential matrices given a (possibly partial) set of measured essential matrices computed independently for pairs of images. We finally use the recovered essential matrices to determine the global positions and orientations of the $n$ cameras. We test our method on common SfM datasets, demonstrating high accuracy while maintaining efficiency and robustness, compared to existing methods.
">Abstract</a>
			<a href="https://arxiv.org/pdf/1904.02663.pdf" target="_blank" class="btn btn-default abstract" ptitle="Algebraic Characterization of Essential Matrices and Their Averaging
in Multiview Settings">Paper</a>
			<!--<a href="https://github.com/YuvalBahat/Confidence_From_Invariance" class="btn btn-default">Code</a>-->
		</div>
        </div>
		
		
		
		<div class="row" id="templatemo_publications_LargeScaleBD">
		<div class="col-md-1"></div>	
		<div class="col-md-5 col-sm-7 col-xs-24">
			<img src="images/cvpr2019.png" alt="image 1">
		</div>
		<div class="col-md-1"></div>	
		<div class="col-md-16">
			<h2>GPSfM: Global Projective SFM Using Algebraic Constraints</h2>
			<h2>on Multi-View Fundamental Matrices</h2>
			<p>Yoni Kasten*, Amnon Geifman*, Meirav Galun and  Ronen Basri  (*equal contribution)<p>
			<tab1>  </tab1>
			<p><i>Computer Vision and Pattern Recognition (CVPR'19), Long Beach 2019</i></p> 
			</p>
			<!--<a class="btn btn-default abstract" ptitle="Abstract will be available soon...">Abstract</a>-->
			<a class="btn btn-default abstract" ptitle="GPSfM: Global Projective SFM Using Algebraic Constraints on Multi-View Fundamental Matrices" 
				abstract="This paper addresses the problem of recovering projective camera matrices from collections of fundamental matrices in multiview settings. We make two main contributions. First, given ${n \choose 2}$ fundamental matrices computed for $n$ images, we provide a complete algebraic characterization in the form of conditions that are both necessary and sufficient to enabling the recovery of camera matrices. These conditions are based on arranging the fundamental matrices as blocks in a single matrix, called the $n$-view fundamental matrix, and characterizing this matrix in terms of the signs of its eigenvalues and rank structures. Secondly, we propose a concrete algorithm for projective structure-from-motion that utilizes this characterization. Given a complete or  partial collection of measured fundamental matrices,  our method seeks camera matrices that minimize a global algebraic error for the measured fundamental matrices. In contrast to existing methods, our optimization, without any initialization,  produces a consistent set of fundamental matrices that corresponds to a unique set of cameras (up to a choice of projective frame).  Our experiments indicate that our method achieves state of the art performance in both accuracy and running time.           
">Abstract</a>
			<a href="https://arxiv.org/pdf/1812.00426.pdf" target="_blank" class="btn btn-default abstract" ptitle="GPSfM: Global Projective SFM Using Algebraic Constraints on Multi-View Fundamental Matrices">Paper</a>
			<a href="https://github.com/amnonge/GPSFM-code" class="btn btn-default" target="_blank">Code</a>
		</div>
        </div>
		
	
		<div class="row" id="templatemo_publications_LargeScaleBD">
		<div class="col-md-1"></div>	
		<div class="col-md-5 col-sm-7 col-xs-24">
			<img src="images/wacv2019.png" alt="image 1">
		</div>
		<div class="col-md-1"></div>	
		<div class="col-md-16">
			<h2>Resultant Based Incremental Recovery of Camera Pose </h2>
			<h2>from Pairwise Matches</h2>
			<p>Yoni Kasten, Meirav Galun and  Ronen Basri  <p>
			<tab1>  </tab1>
			<p><i>Workshop on Applications of Computer Vision (WACV'19), Hilton Waikoloa Village, Hawaii 2019</i></p> 
			</p>
			<!--<a class="btn btn-default abstract" ptitle="Abstract will be available soon...">Abstract</a>-->
			<a class="btn btn-default abstract" ptitle="Resultant Based Incremental Recovery of Camera Pose from Pairwise Matches" 
				abstract="Incremental (online) structure from motion pipelines seek to recover the camera matrix associated with an image I_n given n-1 images, I_1,...,I_n-1, whose camera matrices have already been recovered. In this paper, we introduce a novel solution to the six-point online algorithm to recover the exterior parameters associated with I_n. Our algorithm uses just six corresponding pairs of 2D points, extracted each from I_n and from any of the preceding n-1 images, allowing the recovery of the full six degrees of freedom of the n'th camera, and unlike common methods, does not require tracking feature points in three or more images. Our novel solution is based on constructing a Dixon resultant, yielding a solution method that is both efficient and accurate compared to existing solutions. We further use Bernstein's theorem to prove a tight bound on the number of complex solutions. Our experiments demonstrate the utility of our approach.        
">Abstract</a>
			<a href="https://arxiv.org/pdf/1901.09364.pdf"  target="_blank" class="btn btn-default abstract" ptitle="Resultant Based Incremental Recovery of Camera Pose from Pairwise Matches">Paper</a>
			<a href="https://github.com/ykasten/resultantCamPose" class="btn btn-default" target="_blank">Code</a>
			<a href="https://www.youtube.com/watch?v=B_NzjQFZUN4" class="btn btn-default" target="_blank">Video Lecture</a>
		</div>
        </div>
		
		<div class="row" id="templatemo_publications_LargeScaleBD">
		<div class="col-md-1"></div>	
		<div class="col-md-5 col-sm-7 col-xs-24">
			<img src="images/icip2018.png" alt="image 1">
		</div>
		<div class="col-md-1"></div>	
		<div class="col-md-16">
			<h2>Two View Constraints on the Epipoles from Few Correspondences </h2>
			<p>Yoni Kasten, Michael Werman  <p>
			<tab1>  </tab1>
			<p><i>International Conference on Image Processing (ICIP'18), Athens 2018</i></p> 
			</p>
			<!--<a class="btn btn-default abstract" ptitle="Abstract will be available soon...">Abstract</a>-->
			<a class="btn btn-default abstract" ptitle="Two View Constraints on the Epipoles from Few Correspondences" 
				abstract="In general it requires at least 7 point correspondences to compute the fundamental matrix between views. We use the cross ratio invariance between corresponding epipolar lines, stemming from epipolar line homography, to derive a simple formulation for the relationship between epipoles and corresponding points. We show how it can be used to reduce the number of required points for the epipolar geometry when some information about the epipoles is available and demonstrate this with a buddy search app.  
">Abstract</a>
			<a href="https://arxiv.org/pdf/1810.09496.pdf" target="_blank" class="btn btn-default abstract" ptitle="Two View Constraints on the Epipoles from Few Correspondences">Paper</a>
			<a href="buddy_search.html" class="btn btn-default" target="_blank">Buddy Search Web App (developed with Tomer Hacohen)</a>
		</div>
        </div>
		
		<div class="row" id="templatemo_publications_LargeScaleBD">
		<div class="col-md-1"></div>	
		<div class="col-md-5 col-sm-7 col-xs-24">
			<img src="images/eccv2016.gif" alt="image 1">
		</div>
		<div class="col-md-1"></div>	
		<div class="col-md-16">
			<h2>Fundamental Matrices from Moving Objects Using Line Motion Barcodes </h2>
			<p>Yoni Kasten, Gil Ben-Artzi, Shmuel Peleg and Michael Werman  <p>
			<tab1>  </tab1>
			<p><i>European Conference on Computer Vision (ECCV'16), Amsterdam 2016</i></p> 
			</p>
			<!--<a class="btn btn-default abstract" ptitle="Abstract will be available soon...">Abstract</a>-->
			<a class="btn btn-default abstract" ptitle="Fundamental Matrices from Moving Objects Using Line Motion Barcodes" 
				abstract="Computing the epipolar geometry between cameras with very different viewpoints is often very difficult. The appearance of objects can vary greatly, and it is difficult to find corresponding feature points. Prior methods searched for corresponding epipolar lines using points on the convex hull of the silhouette of a single moving object. These methods fail when the scene includes multiple moving objects. This paper extends previous work to scenes having multiple moving objects by using the “Motion Barcodes”, a temporal signature of lines. Corresponding epipolar lines have similar motion barcodes, and candidate pairs of corresponding epipoar lines are found by the similarity of their motion barcodes. As in previous methods we assume that cameras are relatively stationary and that moving objects have already been extracted using background subtraction.  
">Abstract</a>
			<a href="https://arxiv.org/pdf/1607.07660.pdf" target="_blank" class="btn btn-default abstract" ptitle="Fundamental Matrices from Moving Objects Using Line Motion Barcodes">Paper</a>
		</div>
        </div>
		
			<div class="row" id="templatemo_publications_LargeScaleBD">
		<div class="col-md-1"></div>	
		<div class="col-md-5 col-sm-7 col-xs-24">
			<img src="images/cvpr2016.png" alt="image 1">
		</div>
		<div class="col-md-1"></div>	
		<div class="col-md-16">
			<h2>Camera Calibration From Dynamic Silhouettes Using Motion Barcodes </h2>
			<p>Gil Ben-Artzi,Yoni Kasten, Shmuel Peleg and Michael Werman  <p>
			<tab1>  </tab1>
			<p><i>Computer Vision and Pattern Recognition (CVPR'16), Las Vegas 2016</i></p> 
			</p>
			<!--<a class="btn btn-default abstract" ptitle="Abstract will be available soon...">Abstract</a>-->
			<a class="btn btn-default abstract" ptitle="Camera Calibration From Dynamic Silhouettes Using Motion Barcodes" 
				abstract="Computing the epipolar geometry between cameras with very different viewpoints is often problematic as matching points are hard to find. In these cases, it has been proposed to use information from dynamic objects in the scene for suggesting point and line correspondences. We propose a speed up of about two orders of magnitude, as well as an increase in robustness and accuracy, to methods computing epipolar geometry from dynamic silhouettes based on a new temporal signature, motion barcode for lines. This is a binary temporal sequence for lines, indicating for each frame the existence of at least one foreground pixel on that line. The motion barcodes of two corresponding epipolar lines are very similar so the search for corresponding epipolar lines can be limited to lines having similar barcodes leading to increased speed, accuracy, and robustness in computing the epipolar geometry.  
">Abstract</a>
			<a href="http://openaccess.thecvf.com/content_cvpr_2016/papers/Ben-Artzi_Camera_Calibration_From_CVPR_2016_paper.pdf" target="_blank" class="btn btn-default abstract" ptitle="Camera Calibration From Dynamic Silhouettes Using Motion Barcodes">Paper</a>
		</div>
        </div>
		
</div></section><!-- end of templatemo_publications -->

<br>
<br>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-76024733-2', 'auto');
  ga('send', 'pageview');

</script>
<div id="lightbox" style="display:none;"><a href="#" class="lightbox-close lightbox-button"></a><div class="lightbox-nav" style="display: none;"><a href="#" class="lightbox-previous lightbox-button"></a><a href="#" class="lightbox-next lightbox-button"></a></div><div href="#" class="lightbox-caption"><p></p></div></div></body><!-- Mirrored from www.wisdom.weizmann.ac.il/~shaharko/ by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 06 Apr 2016 11:56:56 GMT --></html><script id="f5_cspm">(function(){var f5_cspm={f5_p:'IOHAGAJCCJLFEHNFGLFAFJIDEHNLBIMHHIENOOIFILJIGLNIECMNPHFJBEPONDKELFKPFDBGPNABIAMBMBFBJOFECDNAOPGEAACPPLEJHOHNIKJKAABBIILKKENCEOAF',setCharAt:function(str,index,chr){if(index>str.length-1)return str;return str.substr(0,index)+chr+str.substr(index+1);},get_byte:function(str,i){var s=(i/16)|0;i=(i&15);s=s*32;return((str.charCodeAt(i+16+s)-65)<<4)|(str.charCodeAt(i+s)-65);},set_byte:function(str,i,b){var s=(i/16)|0;i=(i&15);s=s*32;str=f5_cspm.setCharAt(str,(i+16+s),String.fromCharCode((b>>4)+65));str=f5_cspm.setCharAt(str,(i+s),String.fromCharCode((b&15)+65));return str;},set_latency:function(str,latency){latency=latency&0xffff;str=f5_cspm.set_byte(str,48,(latency>>8));str=f5_cspm.set_byte(str,49,(latency&0xff));str=f5_cspm.set_byte(str,43,2);return str;},wait_perf_data:function(){try{var wp=window.performance.timing;if(wp.loadEventEnd>0){var res=wp.loadEventEnd-wp.navigationStart;if(res<60001){var cookie_val=f5_cspm.set_latency(f5_cspm.f5_p,res);window.document.cookie='f5avr0600570113aaaaaaaaaaaaaaaa='+encodeURIComponent(cookie_val)+';path=/';}
return;}}
catch(err){return;}
setTimeout(f5_cspm.wait_perf_data,100);return;},go:function(){var chunk=window.document.cookie.split(/\s*;\s*/);for(var i=0;i<chunk.length;++i){var pair=chunk[i].split(/\s*=\s*/);if(pair[0]=='f5_cspm'&&pair[1]=='1234')
{var d=new Date();d.setTime(d.getTime()-1000);window.document.cookie='f5_cspm=;expires='+d.toUTCString()+';path=/;';setTimeout(f5_cspm.wait_perf_data,100);}}}}
f5_cspm.go();}());</script>
